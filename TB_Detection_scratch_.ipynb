{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TB_Detection_scratch_.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttfMdvC_P-o4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d93b8c5f-996e-45ab-e6bd-13ac12e4a4ef"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9b5vCCrOUnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import os, sys, random\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_KCsu1zUj83",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract labels from filenane- 0:Normal, 1:Abnormal \n",
        "def get_label(filename):\n",
        "  return int(filename.split(\".png\")[0][-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95HrFE4CXDtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Segregating Normal and Abnormal cases\n",
        "\n",
        "dataset_root = \"/content/drive/My Drive/ChinaSet_Dataset/CXR_png/\"\n",
        "filelist = os.listdir(dataset_root)\n",
        "filelist.sort()\n",
        "\n",
        "pos_ex = []\n",
        "neg_ex = []\n",
        "\n",
        "for file in filelist:\n",
        "  label = get_label(file)\n",
        "  if(label == 0):\n",
        "    pos_ex.append(file)\n",
        "  else:\n",
        "    neg_ex.append(file)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CnLoXkTr3XU",
        "colab_type": "code",
        "outputId": "54aeada0-b7fe-4e15-a7c1-c5e90342d53e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Total No. of examples in the dataset {}\".format(len(filelist)))\n",
        "print(\"No. of Normal cases {}\".format(len(pos_ex)))\n",
        "print(\"No. of Abnormal cases {}\".format(len(neg_ex)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total No. of examples in the dataset 662\n",
            "No. of Normal cases 326\n",
            "No. of Abnormal cases 336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP6V1s38tIQH",
        "colab_type": "code",
        "outputId": "4d7d32e2-cbfa-4d43-f239-d6ab4f75b42b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Creating Test list\n",
        "# we will use 90% data to train and remaining 10% to test\n",
        "No_Test_ex = int(len(filelist)*0.1) # 66 samples for test\n",
        "\n",
        "# we will use 33 Normal and Abnormal samples respectively for testing\n",
        "# we could have randomly chosen 66 samples from the dataset but that would not \n",
        "# gaurantee sampling equal no. of positve and negative cases.\n",
        "test_pos_list = random.sample(pos_ex,int(No_Test_ex/2))\n",
        "test_neg_list = random.sample(neg_ex,int(No_Test_ex/2))\n",
        "\n",
        "test_list = test_pos_list + test_neg_list\n",
        "test_list.sort()\n",
        "print(\"Total No. of test examples {}\".format(len(test_list)))\n",
        "\n",
        "\n",
        "# Creating Train list\n",
        "train_list = []\n",
        "\n",
        "for file in filelist:\n",
        "  if(file not in test_list):\n",
        "    train_list.append(file)\n",
        "train_list.sort()    \n",
        "print(\"Total No. of train examples {}\".format(len(train_list)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total No. of test examples 66\n",
            "Total No. of train examples 596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iqv65BzJvMw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating trainlist.txt and testlist.txt\n",
        "\n",
        "filetrain = open(\"/content/drive/My Drive/train_list.txt\",\"w+\")\n",
        "\n",
        "for file in train_list:\n",
        "  filetrain.write(file+\"\\n\")\n",
        "filetrain.close()\n",
        "\n",
        "filetest = open(\"/content/drive/My Drive/test_list.txt\",\"w+\")\n",
        "\n",
        "for file in test_list:\n",
        "  filetest.write(file+\"\\n\")\n",
        "filetest.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TlxgwPQmpj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_size = 128\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize((img_size, img_size)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bt_5eVLKOhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def default_list_reader(filelist):\n",
        "  imglist = []\n",
        "  with open(filelist,'r') as file:\n",
        "    for line in file.readlines():\n",
        "      imgname,_ = line.split(\"\\n\")\n",
        "      imglist.append(imgname)\n",
        "  imglist.sort()\n",
        "  return imglist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNNKTDeMGU5x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class My_Dataset(Dataset):\n",
        "  def __init__(self, root_dir, filelist = \" \", transform = transforms.ToTensor(), list_reader = default_list_reader):\n",
        "    self.root_dir = root_dir\n",
        "    self.img_names = list_reader(filelist)\n",
        "    self.labels = [get_label(img) for img in self.img_names]\n",
        "    self.transform = transform\n",
        "    \n",
        "  def __getitem__(self,index):\n",
        "    img = Image.open(self.root_dir+self.img_names[index])\n",
        "    img = self.transform(img)\n",
        "    return img,self.labels[index]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.img_names)\n",
        "    \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO_y3h3Xm11v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_root = \"/content/drive/My Drive/ChinaSet_Dataset/CXR_png/\"\n",
        "train_list_path = \"/content/drive/My Drive/train_list.txt\"\n",
        "test_list_path = \"/content/drive/My Drive/test_list.txt\"\n",
        "\n",
        "train_set = My_Dataset(root_dir=dataset_root, filelist = train_list_path, transform = train_transform)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=8, shuffle=True)\n",
        "\n",
        "test_set = My_Dataset(root_dir=dataset_root, filelist = test_list_path, transform = test_transform)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=8, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvZJM09WTLYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(net, self).__init__()\n",
        "        self.C1 = torch.nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3, padding=1, stride=1)\n",
        "        self.model_ft = torchvision.models.resnet18()\n",
        "        self.model_ft.avgpool = torch.nn.AvgPool2d(kernel_size=4, padding=0, stride=2)\n",
        "        self.model_ft.fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(512,256),\n",
        "            torch.nn.Linear(256,2)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        y = self.C1(x)\n",
        "        for _, layer in enumerate(list(self.model_ft.children())[:9]):\n",
        "            y = layer(y)\n",
        "        y = y.squeeze(-1).squeeze(-1)\n",
        "        y = list(self.model_ft.children())[-1](y)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zioeBAvQ5oAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 50\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "Model = net().to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(Model.parameters(), lr=6e-4, weight_decay=1e-2)\n",
        "exp_lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6gsWAjn5_0W",
        "colab_type": "code",
        "outputId": "f98583a9-510d-4ed0-ffc7-d70f1c3f9df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "Model"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "net(\n",
              "  (C1): Conv2d(1, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (model_ft): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AvgPool2d(kernel_size=4, stride=2, padding=0)\n",
              "    (fc): Sequential(\n",
              "      (0): Linear(in_features=512, out_features=256, bias=True)\n",
              "      (1): Linear(in_features=256, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iidd6ypw6GQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loss_track = []\n",
        "test_loss_track = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKnI6KbB7xJa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7dfdf50-f965-44d3-ba1b-3d7637e327f2"
      },
      "source": [
        "for eph in range(n_epochs):\n",
        "    print('epoch : {} ...'.format(eph))\n",
        "    n_correct = 0\n",
        "    avg_loss = 0\n",
        "    n_samples = 0\n",
        "    Model.train()\n",
        "    exp_lr_scheduler.step()\n",
        "    for idx, xy in enumerate(train_loader):\n",
        "        x, y = xy\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        outputs = Model(x)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        n_correct += torch.sum(preds.data == y.data)\n",
        "        avg_loss += loss.item()\n",
        "        n_samples += x.size(0)\n",
        "    avg_loss = avg_loss/n_samples\n",
        "    train_loss_track.append(avg_loss)\n",
        "    print('train avg loss : ', avg_loss)\n",
        "    print('num of correct samples : {}/{}'.format(n_correct, n_samples))\n",
        "    \n",
        "    n_correct = 0\n",
        "    avg_loss = 0\n",
        "    n_samples = 0\n",
        "    gt_labels = []\n",
        "    pred_labels = []\n",
        "    Model.eval()\n",
        "    for idx, xy in enumerate(test_loader):\n",
        "        x, y = xy\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "        outputs = Model(x)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, y)\n",
        "        \n",
        "        n_correct += torch.sum(preds.data == y.data)\n",
        "        gt_labels += list(y.data.cpu().numpy())\n",
        "        pred_labels += list(preds.data.cpu().numpy())\n",
        "        avg_loss += loss.item()\n",
        "        n_samples += x.size(0)\n",
        "    avg_loss = avg_loss/n_samples\n",
        "    test_loss_track.append(avg_loss)\n",
        "    print('test avg loss : ', avg_loss)\n",
        "    print('num of correct samples : {}/{}'.format(n_correct, n_samples))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch : 0 ...\n",
            "train avg loss :  0.07729496471833863\n",
            "num of correct samples : 434/596\n",
            "test avg loss :  0.09654086737921744\n",
            "num of correct samples : 51/66\n",
            "epoch : 1 ...\n",
            "train avg loss :  0.06803144787081936\n",
            "num of correct samples : 447/596\n",
            "test avg loss :  0.06551063467155803\n",
            "num of correct samples : 54/66\n",
            "epoch : 2 ...\n",
            "train avg loss :  0.06564438993098752\n",
            "num of correct samples : 440/596\n",
            "test avg loss :  0.11421398186322415\n",
            "num of correct samples : 41/66\n",
            "epoch : 3 ...\n",
            "train avg loss :  0.06634245665381419\n",
            "num of correct samples : 443/596\n",
            "test avg loss :  0.07836960346409769\n",
            "num of correct samples : 45/66\n",
            "epoch : 4 ...\n",
            "train avg loss :  0.06912364725698561\n",
            "num of correct samples : 448/596\n",
            "test avg loss :  0.09513232134508365\n",
            "num of correct samples : 36/66\n",
            "epoch : 5 ...\n",
            "train avg loss :  0.06558470332982556\n",
            "num of correct samples : 441/596\n",
            "test avg loss :  0.06807676115722368\n",
            "num of correct samples : 52/66\n",
            "epoch : 6 ...\n",
            "train avg loss :  0.06585026137380792\n",
            "num of correct samples : 453/596\n",
            "test avg loss :  0.0675084667675423\n",
            "num of correct samples : 51/66\n",
            "epoch : 7 ...\n",
            "train avg loss :  0.06461927879776731\n",
            "num of correct samples : 472/596\n",
            "test avg loss :  0.1644502647898414\n",
            "num of correct samples : 42/66\n",
            "epoch : 8 ...\n",
            "train avg loss :  0.06436499620744046\n",
            "num of correct samples : 464/596\n",
            "test avg loss :  0.05339612157055826\n",
            "num of correct samples : 57/66\n",
            "epoch : 9 ...\n",
            "train avg loss :  0.0666737779724918\n",
            "num of correct samples : 455/596\n",
            "test avg loss :  0.06598200016852582\n",
            "num of correct samples : 51/66\n",
            "epoch : 10 ...\n",
            "train avg loss :  0.06617916720425522\n",
            "num of correct samples : 460/596\n",
            "test avg loss :  0.1430152812690446\n",
            "num of correct samples : 33/66\n",
            "epoch : 11 ...\n",
            "train avg loss :  0.07372139839317975\n",
            "num of correct samples : 431/596\n",
            "test avg loss :  0.06587493419647217\n",
            "num of correct samples : 53/66\n",
            "epoch : 12 ...\n",
            "train avg loss :  0.06530470158529762\n",
            "num of correct samples : 460/596\n",
            "test avg loss :  0.08589922614169843\n",
            "num of correct samples : 41/66\n",
            "epoch : 13 ...\n",
            "train avg loss :  0.06884350692665817\n",
            "num of correct samples : 453/596\n",
            "test avg loss :  0.06248861009424383\n",
            "num of correct samples : 51/66\n",
            "epoch : 14 ...\n",
            "train avg loss :  0.06766502696695743\n",
            "num of correct samples : 450/596\n",
            "test avg loss :  0.14576676262147498\n",
            "num of correct samples : 33/66\n",
            "epoch : 15 ...\n",
            "train avg loss :  0.06422469524929188\n",
            "num of correct samples : 463/596\n",
            "test avg loss :  0.08429697065642386\n",
            "num of correct samples : 44/66\n",
            "epoch : 16 ...\n",
            "train avg loss :  0.06724997339832703\n",
            "num of correct samples : 460/596\n",
            "test avg loss :  0.11939318590995038\n",
            "num of correct samples : 38/66\n",
            "epoch : 17 ...\n",
            "train avg loss :  0.06689068790050161\n",
            "num of correct samples : 455/596\n",
            "test avg loss :  0.08149072573040471\n",
            "num of correct samples : 40/66\n",
            "epoch : 18 ...\n",
            "train avg loss :  0.06406048395289671\n",
            "num of correct samples : 464/596\n",
            "test avg loss :  0.06134411331379053\n",
            "num of correct samples : 50/66\n",
            "epoch : 19 ...\n",
            "train avg loss :  0.06670716314907842\n",
            "num of correct samples : 458/596\n",
            "test avg loss :  0.10773104993682919\n",
            "num of correct samples : 39/66\n",
            "epoch : 20 ...\n",
            "train avg loss :  0.06330208470357344\n",
            "num of correct samples : 455/596\n",
            "test avg loss :  0.13877912238240242\n",
            "num of correct samples : 40/66\n",
            "epoch : 21 ...\n",
            "train avg loss :  0.06710112142382853\n",
            "num of correct samples : 454/596\n",
            "test avg loss :  0.12619894788120734\n",
            "num of correct samples : 34/66\n",
            "epoch : 22 ...\n",
            "train avg loss :  0.06035326661279537\n",
            "num of correct samples : 462/596\n",
            "test avg loss :  0.06405866236397714\n",
            "num of correct samples : 45/66\n",
            "epoch : 23 ...\n",
            "train avg loss :  0.06384061211907624\n",
            "num of correct samples : 469/596\n",
            "test avg loss :  0.11235323187076685\n",
            "num of correct samples : 33/66\n",
            "epoch : 24 ...\n",
            "train avg loss :  0.06415812251151808\n",
            "num of correct samples : 461/596\n",
            "test avg loss :  0.05480546436526559\n",
            "num of correct samples : 55/66\n",
            "epoch : 25 ...\n",
            "train avg loss :  0.059894984925553306\n",
            "num of correct samples : 469/596\n",
            "test avg loss :  0.06034814498641274\n",
            "num of correct samples : 53/66\n",
            "epoch : 26 ...\n",
            "train avg loss :  0.0633092661882007\n",
            "num of correct samples : 471/596\n",
            "test avg loss :  0.15622803489818718\n",
            "num of correct samples : 34/66\n",
            "epoch : 27 ...\n",
            "train avg loss :  0.06293195068536189\n",
            "num of correct samples : 475/596\n",
            "test avg loss :  0.09109932093909293\n",
            "num of correct samples : 33/66\n",
            "epoch : 28 ...\n",
            "train avg loss :  0.058586914042298426\n",
            "num of correct samples : 480/596\n",
            "test avg loss :  0.06230662379300955\n",
            "num of correct samples : 53/66\n",
            "epoch : 29 ...\n",
            "train avg loss :  0.0609848887078314\n",
            "num of correct samples : 469/596\n",
            "test avg loss :  0.061931703352566925\n",
            "num of correct samples : 54/66\n",
            "epoch : 30 ...\n",
            "train avg loss :  0.06158085169908184\n",
            "num of correct samples : 465/596\n",
            "test avg loss :  0.09974750966736765\n",
            "num of correct samples : 37/66\n",
            "epoch : 31 ...\n",
            "train avg loss :  0.05875854964224284\n",
            "num of correct samples : 471/596\n",
            "test avg loss :  0.05420347393462152\n",
            "num of correct samples : 55/66\n",
            "epoch : 32 ...\n",
            "train avg loss :  0.05944530655873702\n",
            "num of correct samples : 468/596\n",
            "test avg loss :  0.08227418724334601\n",
            "num of correct samples : 42/66\n",
            "epoch : 33 ...\n",
            "train avg loss :  0.06053376042802862\n",
            "num of correct samples : 474/596\n",
            "test avg loss :  0.07013834222699657\n",
            "num of correct samples : 50/66\n",
            "epoch : 34 ...\n",
            "train avg loss :  0.055040437978186064\n",
            "num of correct samples : 486/596\n",
            "test avg loss :  0.04561379032604622\n",
            "num of correct samples : 56/66\n",
            "epoch : 35 ...\n",
            "train avg loss :  0.05364360942836576\n",
            "num of correct samples : 488/596\n",
            "test avg loss :  0.05046157854976076\n",
            "num of correct samples : 56/66\n",
            "epoch : 36 ...\n",
            "train avg loss :  0.053213288495004576\n",
            "num of correct samples : 489/596\n",
            "test avg loss :  0.09490812344081474\n",
            "num of correct samples : 38/66\n",
            "epoch : 37 ...\n",
            "train avg loss :  0.053207285477211014\n",
            "num of correct samples : 490/596\n",
            "test avg loss :  0.061398195272142235\n",
            "num of correct samples : 48/66\n",
            "epoch : 38 ...\n",
            "train avg loss :  0.05403885027806231\n",
            "num of correct samples : 489/596\n",
            "test avg loss :  0.04757631254015547\n",
            "num of correct samples : 57/66\n",
            "epoch : 39 ...\n",
            "train avg loss :  0.05306851356321533\n",
            "num of correct samples : 488/596\n",
            "test avg loss :  0.13432446460832248\n",
            "num of correct samples : 36/66\n",
            "epoch : 40 ...\n",
            "train avg loss :  0.05090133702044919\n",
            "num of correct samples : 495/596\n",
            "test avg loss :  0.04918596441998626\n",
            "num of correct samples : 54/66\n",
            "epoch : 41 ...\n",
            "train avg loss :  0.05060054368070708\n",
            "num of correct samples : 488/596\n",
            "test avg loss :  0.05892572484233163\n",
            "num of correct samples : 52/66\n",
            "epoch : 42 ...\n",
            "train avg loss :  0.046243278547221385\n",
            "num of correct samples : 502/596\n",
            "test avg loss :  0.05395697791016463\n",
            "num of correct samples : 54/66\n",
            "epoch : 43 ...\n",
            "train avg loss :  0.04056803710858694\n",
            "num of correct samples : 517/596\n",
            "test avg loss :  0.04568928999431206\n",
            "num of correct samples : 55/66\n",
            "epoch : 44 ...\n",
            "train avg loss :  0.040491573050018125\n",
            "num of correct samples : 526/596\n",
            "test avg loss :  0.047194464414408714\n",
            "num of correct samples : 56/66\n",
            "epoch : 45 ...\n",
            "train avg loss :  0.03802787232518996\n",
            "num of correct samples : 517/596\n",
            "test avg loss :  0.04993498246326591\n",
            "num of correct samples : 54/66\n",
            "epoch : 46 ...\n",
            "train avg loss :  0.03659080586477414\n",
            "num of correct samples : 530/596\n",
            "test avg loss :  0.05028252777728168\n",
            "num of correct samples : 54/66\n",
            "epoch : 47 ...\n",
            "train avg loss :  0.03892998152331218\n",
            "num of correct samples : 519/596\n",
            "test avg loss :  0.050169864161448044\n",
            "num of correct samples : 54/66\n",
            "epoch : 48 ...\n",
            "train avg loss :  0.036333195927659136\n",
            "num of correct samples : 528/596\n",
            "test avg loss :  0.04946154310847774\n",
            "num of correct samples : 54/66\n",
            "epoch : 49 ...\n",
            "train avg loss :  0.03674645144367378\n",
            "num of correct samples : 534/596\n",
            "test avg loss :  0.04860066374142965\n",
            "num of correct samples : 56/66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuRUgFfV76MN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "57f29974-533c-4e43-abdc-499c338e4af9"
      },
      "source": [
        "plt.plot(train_loss_track, 'b')\n",
        "plt.plot(test_loss_track, 'r')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('avg loss')\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUbFQFEVRfFGxUBRFUXxRsVAURVF8+X+uXH8r7KIDjwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p90uK1CG79_k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "a1eb613f-cd99-4359-b77b-e7bcabbc8a5b"
      },
      "source": [
        "target_names = ['No TB', 'TB']\n",
        "print(classification_report(gt_labels, pred_labels, target_names=target_names))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       No TB       0.90      0.79      0.84        33\n",
            "          TB       0.81      0.91      0.86        33\n",
            "\n",
            "    accuracy                           0.85        66\n",
            "   macro avg       0.85      0.85      0.85        66\n",
            "weighted avg       0.85      0.85      0.85        66\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YtXZEms9Kc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_save_name = 'model_res_notpre.pt' \n",
        "path = F\"/content/drive/My Drive/{model_save_name}\" \n",
        "torch.save(Model.state_dict(), path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}